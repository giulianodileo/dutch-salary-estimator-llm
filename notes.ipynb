{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347a7348",
   "metadata": {},
   "source": [
    "# Clean Salary Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75de835d",
   "metadata": {},
   "source": [
    "## Glassdoor salary cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fdb7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def round_to_decade(value: float) -> float:\n",
    "    \"\"\"Round a float to the closest decade as a float.\"\"\"\n",
    "    return float(round(value / 10) * 10)\n",
    "\n",
    "def clean_job_data(\n",
    "    json_file_path=\"raw_data/data_dict.json\",\n",
    "    output_file_path=\"raw_data/data_dict_clean.json\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Cleans job data by:\n",
    "    1. Replacing null 'position' with 'AI Engineer'\n",
    "    2. Removing old 'salary' field\n",
    "    3. Renaming positions:\n",
    "       - 'Back End Developer/ Engineer' -> 'Backend Engineer'\n",
    "       - 'Front End Developer / Engineer' -> 'Frontend Engineer'\n",
    "    4. Restructuring data into:\n",
    "       {\n",
    "         \"position\": ...,\n",
    "         \"seniority\": ...,\n",
    "         \"compensation\": {\n",
    "            \"currency\": \"EUR\",\n",
    "            \"period\": \"monthly\",\n",
    "            \"min_amount\": ...,\n",
    "            \"avg_amount\": ...,\n",
    "            \"max_amount\": ...\n",
    "         },\n",
    "         \"source_url\": ...,\n",
    "         \"source_site\": ...\n",
    "       }\n",
    "    5. Converts yearly values to monthly by dividing by 12,\n",
    "       rounding each amount to the closest decade,\n",
    "       and changing period -> \"monthly\".\n",
    "    \"\"\"\n",
    "    with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    cleaned = []\n",
    "    for entry in data:\n",
    "        # --- Fix position ---\n",
    "        position = entry.get(\"position\")\n",
    "        if position is None:\n",
    "            position = \"AI Engineer\"\n",
    "        elif position == \"Back End Developer/ Engineer\":\n",
    "            position = \"Backend Engineer\"\n",
    "        elif position == \"Front End Developer / Engineer\":\n",
    "            position = \"Frontend Engineer\"\n",
    "\n",
    "        # --- Seniority ---\n",
    "        seniority = entry.get(\"seniority\")\n",
    "\n",
    "        # --- Compensation ---\n",
    "        salary_str = entry.get(\"salary\", \"\")\n",
    "        period = \"monthly\" if \"mnd\" in salary_str else \"yearly\"\n",
    "\n",
    "        min_amount = entry.get(\"min_amount\")\n",
    "        avg_amount = entry.get(\"avg_amount\")\n",
    "        max_amount = entry.get(\"max_amount\")\n",
    "\n",
    "        if period == \"yearly\":\n",
    "            # Convert to monthly & round to closest decade\n",
    "            min_amount = round_to_decade(min_amount / 12) if min_amount else None\n",
    "            avg_amount = round_to_decade(avg_amount / 12) if avg_amount else None\n",
    "            max_amount = round_to_decade(max_amount / 12) if max_amount else None\n",
    "            period = \"monthly\"  # update period\n",
    "\n",
    "        compensation = {\n",
    "            \"currency\": \"EUR\",\n",
    "            \"period\": period,\n",
    "            \"min_amount\": min_amount,\n",
    "            \"avg_amount\": avg_amount,\n",
    "            \"max_amount\": max_amount,\n",
    "        }\n",
    "\n",
    "        cleaned.append({\n",
    "            \"position\": position,\n",
    "            \"seniority\": seniority,\n",
    "            \"compensation\": compensation,\n",
    "            \"source_url\": entry.get(\"source_url\"),\n",
    "            \"source_site\": entry.get(\"source_site\")\n",
    "        })\n",
    "\n",
    "    # Save updated JSON\n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(cleaned, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Cleaned data saved to {output_file_path}\")\n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93b4798e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to raw_data/data_dict_clean.json\n"
     ]
    }
   ],
   "source": [
    "cleaned_data = clean_job_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7444499a",
   "metadata": {},
   "source": [
    "## Payscale salary cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42a38268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def round_to_decade(value: float) -> float:\n",
    "    \"\"\"Round a float to the closest decade as a float.\"\"\"\n",
    "    return float(round(value / 10) * 10)\n",
    "\n",
    "def normalize_payscale_salaries(\n",
    "    json_file_path=\"raw_data/payscale_tech_salaries.json\",\n",
    "    output_file_path=\"raw_data/ps_normalised_salaries.json\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Normalizes Payscale salaries by:\n",
    "    1. Renaming positions:\n",
    "       - 'Back End Developer/ Engineer' -> 'Backend Engineer'\n",
    "       - 'Front End Developer / Engineer' -> 'Frontend Engineer'\n",
    "    2. Converting yearly compensation into monthly:\n",
    "       - Divide by 12\n",
    "       - Round to closest decade\n",
    "       - Change period to 'monthly'\n",
    "    \"\"\"\n",
    "    with open(json_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for entry in data:\n",
    "        # --- Rename positions ---\n",
    "        if entry.get(\"position\") == \"Back End Developer/ Engineer\":\n",
    "            entry[\"position\"] = \"Backend Engineer\"\n",
    "        elif entry.get(\"position\") == \"Front End Developer / Engineer\":\n",
    "            entry[\"position\"] = \"Frontend Engineer\"\n",
    "\n",
    "        # --- Compensation conversion ---\n",
    "        comp = entry.get(\"compensation\", {})\n",
    "        if comp.get(\"period\") == \"yearly\":\n",
    "            for key in [\"min_amount\", \"avg_amount\", \"max_amount\"]:\n",
    "                if comp.get(key) is not None:\n",
    "                    comp[key] = round_to_decade(comp[key] / 12)\n",
    "            comp[\"period\"] = \"monthly\"\n",
    "\n",
    "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Normalized data saved to {output_file_path}\")\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bd6478c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized data saved to raw_data/ps_normalised_salaries.json\n"
     ]
    }
   ],
   "source": [
    "ps_cleaned_data = normalize_payscale_salaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59bb72a",
   "metadata": {},
   "source": [
    "# Utilities cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb19e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdecca48",
   "metadata": {},
   "source": [
    "### Scraper Function (from Thabiso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ce596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- add to requirements if you haven't ---\n",
    "# pip install -qU requests beautifulsoup4 pydantic langchain langchain-core \"langchain[google-genai]\" python-dotenv\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from typing import List, Optional, Dict\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "from pydantic import BaseModel\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "# Load .env for GOOGLE_API_KEY\n",
    "load_dotenv()\n",
    "# -----------------------------\n",
    "# Pydantic Schema for Utilities\n",
    "# -----------------------------\n",
    "class ExpenseItem(BaseModel):\n",
    "    category: str                    # \"Gas\", \"Electricity\", \"Water\"\n",
    "    value: float                      # cost as float\n",
    "    period: str                       # e.g., \"per month\"\n",
    "    year: Optional[int] = None        # Year as integer\n",
    "    source_url: str\n",
    "class UtilitiesPage(BaseModel):\n",
    "    expenses: List[ExpenseItem]\n",
    "# -----------------------------\n",
    "# LangChain LLM setup\n",
    "# -----------------------------\n",
    "llm = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")\n",
    "structured_llm = llm.with_structured_output(UtilitiesPage)\n",
    "# -----------------------------\n",
    "# HTTP Session + retries + headers\n",
    "# -----------------------------\n",
    "DEFAULT_USER_AGENTS = [\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\",\n",
    "]\n",
    "BASE_HEADERS = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Cache-Control\": \"no-cache\",\n",
    "    \"Pragma\": \"no-cache\",\n",
    "    \"DNT\": \"1\",\n",
    "}\n",
    "def build_session() -> requests.Session:\n",
    "    s = requests.Session()\n",
    "    retries = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=1.2,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\", \"HEAD\", \"OPTIONS\"]\n",
    "    )\n",
    "    s.mount(\"https://\", HTTPAdapter(max_retries=retries))\n",
    "    s.mount(\"http://\", HTTPAdapter(max_retries=retries))\n",
    "    s.headers.update({\n",
    "        **BASE_HEADERS,\n",
    "        \"User-Agent\": random.choice(DEFAULT_USER_AGENTS),\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "    })\n",
    "    return s\n",
    "# -----------------------------\n",
    "# Fetch HTML + convert to text\n",
    "# -----------------------------\n",
    "def fetch_html(url: str, session: Optional[requests.Session] = None, timeout: int = 20) -> str:\n",
    "    sess = session or build_session()\n",
    "    r = sess.get(url, timeout=timeout)\n",
    "    if r.status_code == 403:\n",
    "        raise PermissionError(f\"403 Forbidden on {url}\")\n",
    "    r.raise_for_status()\n",
    "    return r.text\n",
    "def html_to_text(html: str, max_chars: int = 15000) -> str:\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    for tag in soup([\"script\", \"style\", \"noscript\", \"template\"]):\n",
    "        tag.decompose()\n",
    "    text = soup.get_text(separator=\" \", strip=True)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    if len(text) > max_chars:\n",
    "        text = text[: int(max_chars * 0.7)] + \" ... [TRUNCATED] ... \" + text[-int(max_chars * 0.3):]\n",
    "    return text\n",
    "# -----------------------------\n",
    "# Extraction system hint\n",
    "# -----------------------------\n",
    "EXTRACTION_SYSTEM_HINT = \"\"\"\n",
    "You are an information extractor for household utility costs from Dutch consumer pages (e.g., Nibud).\n",
    "Return exactly three ExpenseItem entries for categories:\n",
    "- Gas (apartment/flat value)\n",
    "- Electricity (average household)\n",
    "- Water (average household)\n",
    "STRICT RULES for each ExpenseItem:\n",
    "- category: must be exactly one of [\"Gas\",\"Electricity\",\"Water\"].\n",
    "- value: must be a float greater than 0 if mentioned in text.\n",
    "         If multiple values are shown (e.g., water for different household sizes),\n",
    "         pick the average monthly cost across the table.\n",
    "         If unsure, pick the 1-person household monthly cost.\n",
    "- period: must always be non-empty.\n",
    "          Use the exact text if available (\"per month\", \"per year\").\n",
    "          If unclear, default to \"per month\".\n",
    "- year: integer if explicitly stated in the text, otherwise null.\n",
    "- source_url: must be the input URL.\n",
    "Do not invent or guess costs.\n",
    "Do not leave any field blank.\n",
    "Deduplicate entries so only one per category.\n",
    "\"\"\"\n",
    "# -----------------------------\n",
    "# Helper: ensure all categories present and enforce defaults\n",
    "# -----------------------------\n",
    "def ensure_all_categories(expenses: List[ExpenseItem], source_url: str, page_text: str = \"\") -> List[ExpenseItem]:\n",
    "    required = {\"Gas\", \"Electricity\", \"Water\"}\n",
    "    present = {e.category for e in expenses}\n",
    "    for e in expenses:\n",
    "        if not e.period or e.period.strip() == \"\":\n",
    "            e.period = \"per month\"\n",
    "        # keep LLM extracted values if >0, only fallback later\n",
    "        if e.value <= 0:\n",
    "            if e.category == \"Water\":\n",
    "                # Fallback: parse water table from page text\n",
    "                water_matches = re.findall(r\"\\b\\d{1,3},\\d{1,2}\\b\", page_text)\n",
    "                if water_matches:\n",
    "                    # Convert e.g. \"17,50\" -> 17.50\n",
    "                    values = [float(m.replace(\",\", \".\")) for m in water_matches]\n",
    "                    e.value = round(sum(values) / len(values), 2)  # mean of table\n",
    "                else:\n",
    "                    e.value = -1.0  # truly missing\n",
    "            else:\n",
    "                e.value = -1.0\n",
    "    missing = required - present\n",
    "    for cat in missing:\n",
    "        fallback_value = -1.0\n",
    "        if cat == \"Water\":\n",
    "            water_matches = re.findall(r\"\\b\\d{1,3},\\d{1,2}\\b\", page_text)\n",
    "            if water_matches:\n",
    "                values = [float(m.replace(\",\", \".\")) for m in water_matches]\n",
    "                fallback_value = round(sum(values) / len(values), 2)\n",
    "        expenses.append(ExpenseItem(\n",
    "            category=cat,\n",
    "            value=fallback_value,\n",
    "            period=\"per month\",\n",
    "            year=None,\n",
    "            source_url=source_url\n",
    "        ))\n",
    "    return expenses\n",
    "# -----------------------------\n",
    "# Extract using LLM (updated to pass page_text to ensure_all_categories)\n",
    "# -----------------------------\n",
    "def extract_expenses_from_text(page_text: str, source_url: str) -> UtilitiesPage:\n",
    "    prompt = f\"{EXTRACTION_SYSTEM_HINT}\\nSOURCE URL:\\n{source_url}\\nPAGE TEXT:\\n{page_text}\"\n",
    "    parsed: UtilitiesPage = structured_llm.invoke(prompt)\n",
    "    for e in parsed.expenses:\n",
    "        e.source_url = source_url\n",
    "    parsed.expenses = ensure_all_categories(parsed.expenses, source_url, page_text)\n",
    "    return parsed\n",
    "def dedupe_expenses(items: List[ExpenseItem]) -> List[ExpenseItem]:\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for e in items:\n",
    "        key = (e.category.strip().lower(), str(e.value), e.period.strip().lower())\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            out.append(e)\n",
    "    return out\n",
    "# -----------------------------\n",
    "# Hybrid orchestrator\n",
    "# -----------------------------\n",
    "def extract_from_inputs(\n",
    "    urls: Optional[List[str]] = None,\n",
    "    files: Optional[List[str]] = None,\n",
    "    raw_html_blobs: Optional[List[Dict[str, str]]] = None,\n",
    "    polite_delay_s: float = 2.5,\n",
    ") -> List[ExpenseItem]:\n",
    "    session = build_session()\n",
    "    urls = urls or []\n",
    "    files = files or []\n",
    "    raw_html_blobs = raw_html_blobs or []\n",
    "    all_expenses: List[ExpenseItem] = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            html = fetch_html(url, session=session)\n",
    "            text = html_to_text(html)\n",
    "            all_expenses.extend(extract_expenses_from_text(text, source_url=url).expenses)\n",
    "            time.sleep(polite_delay_s + random.random())\n",
    "        except Exception as e:\n",
    "            print(f\"[URL Error] {url}: {e}\")\n",
    "    for path in files:\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                html = f.read()\n",
    "            text = html_to_text(html)\n",
    "            all_expenses.extend(extract_expenses_from_text(text, source_url=f\"file://{os.path.abspath(path)}\").expenses)\n",
    "        except Exception as e:\n",
    "            print(f\"[File Error] {path}: {e}\")\n",
    "    for blob in raw_html_blobs:\n",
    "        try:\n",
    "            html = blob.get(\"html\", \"\")\n",
    "            src = blob.get(\"source_url\", \"about:blank\")\n",
    "            text = html_to_text(html)\n",
    "            all_expenses.extend(extract_expenses_from_text(text, source_url=src).expenses)\n",
    "        except Exception as e:\n",
    "            print(f\"[Raw HTML Error] {src}: {e}\")\n",
    "    return dedupe_expenses(all_expenses)\n",
    "# -----------------------------\n",
    "# Runner\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    URLS = [\n",
    "        \"https://www.nibud.nl/onderwerpen/uitgaven/kosten-energie-water/\"\n",
    "    ]\n",
    "    FILES = []\n",
    "    RAW_HTML = []\n",
    "    results = extract_from_inputs(urls=URLS, files=FILES, raw_html_blobs=RAW_HTML)\n",
    "    print(json.dumps([e.model_dump() for e in results], indent=2, ensure_ascii=False))\n",
    "    with open(\"utilities_expenses.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump([e.model_dump() for e in results], f, ensure_ascii=False, indent=4)\n",
    "    print(\"\\n:white_check_mark: Saved extracted data to utilities_expenses.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3982dcc",
   "metadata": {},
   "source": [
    "## Clean Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9765f64",
   "metadata": {},
   "source": [
    "### Update monthly period from \"per month\" to \"monthly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "582f7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_period(data):\n",
    "    for item in data:\n",
    "        if item.get(\"period\") == \"per month\":\n",
    "            item[\"period\"] = \"monthly\"\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba87a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"category\": \"Gas\",\n",
      "        \"value\": 110.0,\n",
      "        \"period\": \"monthly\",\n",
      "        \"year\": 2025,\n",
      "        \"source_url\": \"https://www.nibud.nl/onderwerpen/uitgaven/kosten-energie-water/\"\n",
      "    },\n",
      "    {\n",
      "        \"category\": \"Electricity\",\n",
      "        \"value\": 54.5,\n",
      "        \"period\": \"monthly\",\n",
      "        \"year\": 2025,\n",
      "        \"source_url\": \"https://www.nibud.nl/onderwerpen/uitgaven/kosten-energie-water/\"\n",
      "    },\n",
      "    {\n",
      "        \"category\": \"Water\",\n",
      "        \"value\": 25.9,\n",
      "        \"period\": \"monthly\",\n",
      "        \"year\": 2025,\n",
      "        \"source_url\": \"https://www.nibud.nl/onderwerpen/uitgaven/kosten-energie-water/\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_data = [\n",
    "    {\n",
    "        \"category\": \"Gas\",\n",
    "        \"value\": 110.0,\n",
    "        \"period\": \"per month\",\n",
    "        \"year\": 2025,\n",
    "        \"source_url\": \"https://www.nibud.nl/onderwerpen/uitgaven/kosten-energie-water/\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Electricity\",\n",
    "        \"value\": 54.5,\n",
    "        \"period\": \"per month\",\n",
    "        \"year\": 2025,\n",
    "        \"source_url\": \"https://www.nibud.nl/onderwerpen/uitgaven/kosten-energie-water/\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Water\",\n",
    "        \"value\": 25.9,\n",
    "        \"period\": \"per month\",\n",
    "        \"year\": 2025,\n",
    "        \"source_url\": \"https://www.nibud.nl/onderwerpen/uitgaven/kosten-energie-water/\"\n",
    "    }\n",
    "]\n",
    "\n",
    "updated_data = update_period(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4a571",
   "metadata": {},
   "source": [
    "Save file in the *data* folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cab6128c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved at: data/clean_utilities.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Write updated_data to JSON file\n",
    "with open(\"data/clean_utilities.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(updated_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"File saved at: data/clean_utilities.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5cfda7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dutch-salary-estimator-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
